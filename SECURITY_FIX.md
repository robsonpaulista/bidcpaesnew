# üîí Corre√ß√µes de Seguran√ßa Cr√≠ticas - LLM Mapper

## üö® Problema Identificado

O c√≥digo estava rodando no **frontend (Vite)**, expondo a API key do Groq:
- ‚ùå `VITE_LLM_API_KEY` √© injetada no bundle do cliente
- ‚ùå Qualquer pessoa pode inspecionar e reutilizar a key
- ‚ùå Perda de governan√ßa (rate limit, cache central, auditoria)

## ‚úÖ Solu√ß√£o Implementada

### 1. Backend (Vercel Serverless Functions)

Criada a estrutura de API routes:
- `api/orchestrator/ask.ts` - Serverless function do Vercel
- Roda no **backend** (seguro)
- API key fica em `process.env.GROQ_API_KEY` (n√£o exposta)

### 2. Frontend Atualizado

- `src/services/orchestrator/api.ts` agora chama `/api/orchestrator/ask`
- Remove execu√ß√£o local da orquestra√ß√£o
- Fallback apenas em desenvolvimento

### 3. Corre√ß√µes Cr√≠ticas no Parser

#### A) Confidence (nullish coalescing)
```typescript
// ANTES (ERRADO):
confidence: Math.min(1, Math.max(0, parsed.confidence || 0.8))

// DEPOIS (CORRETO):
const rawC = parsed.confidence ?? 0.8
const c = Number(rawC)
confidence: Number.isFinite(c) ? Math.min(1, Math.max(0, c)) : 0.8
```

#### B) Parse JSON (sem regex primeiro)
```typescript
// ANTES: regex primeiro
const jsonMatch = content.match(/\{[\s\S]*\}/)

// DEPOIS: JSON.parse direto (j√° for√ßa JSON com response_format)
try {
  parsed = JSON.parse(content)
} catch {
  // Fallback regex apenas se necess√°rio
  const jsonMatch = content.match(/\{[\s\S]*\}/)
  ...
}
```

#### C) Valida√ß√£o de Entities
```typescript
// Valida que entities √© objeto v√°lido
const entities = (typeof parsed.entities === 'object' && parsed.entities !== null && !Array.isArray(parsed.entities))
  ? parsed.entities
  : {}
```

### 4. Timeout e AbortController

Adicionado timeout de 3 segundos:
```typescript
const controller = new AbortController()
const timeoutId = setTimeout(() => controller.abort(), 3000)
```

## üìã Configura√ß√£o no Vercel

### Vari√°veis de Ambiente

No Vercel Dashboard ‚Üí Settings ‚Üí Environment Variables:

```
GROQ_API_KEY=gsk_...
LLM_PROVIDER=groq
LLM_MODEL=llama-3.1-8b-instant
```

**IMPORTANTE**: 
- ‚ùå N√ÉO use `VITE_LLM_API_KEY` (exp√µe no frontend)
- ‚úÖ Use `GROQ_API_KEY` ou `LLM_API_KEY` (seguro no backend)

### Deploy

```bash
vercel deploy
```

O Vercel automaticamente detecta a pasta `api/` e cria Serverless Functions.

## üîç Verifica√ß√£o

1. **Frontend n√£o tem acesso √† key**:
   - Inspecione o bundle: `dist/assets/*.js`
   - Procure por "gsk_" ou "GROQ_API_KEY"
   - N√£o deve encontrar nada

2. **Backend tem acesso**:
   - Logs do Vercel Functions
   - `process.env.GROQ_API_KEY` existe no backend

3. **API funciona**:
   - Teste: `POST /api/orchestrator/ask`
   - Deve retornar resposta da orquestra√ß√£o

## ‚ö†Ô∏è Pr√≥ximos Passos (Recomendados)

1. **Cache no Backend**: Redis (Upstash) ou Supabase
2. **Auditoria**: Log de todas as chamadas LLM (provider/model/latency)
3. **Rate Limiting**: Por usu√°rio/IP no backend
4. **Normaliza√ß√£o de Entidades**: Fun√ß√£o `normalizeEntities()` no maestro

## üìù Arquivos Modificados

- ‚úÖ `api/orchestrator/ask.ts` (novo)
- ‚úÖ `src/services/orchestrator/llm-mapper.ts` (corre√ß√µes)
- ‚úÖ `src/services/orchestrator/api.ts` (chama API)
- ‚úÖ `vercel.json` (configura√ß√£o de functions)



